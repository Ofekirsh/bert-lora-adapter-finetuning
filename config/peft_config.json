{
  "method": "lora",
  "lora": {
    "r": 8,
    "alpha": 16,
    "dropout": 0.1,
    "bias": "none",
    "task_type": "SEQ_CLS"
  },
  "adapter": {
    "num_virtual_tokens": 20,
    "task_type": "SEQ_CLS"
  },
  "model_name": "bert-base-uncased",
  "num_labels": 2
}
